<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ImageTx</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;
        }
    </style>
</head>
<body class="bg-gray-100 min-h-screen flex items-center justify-center">
    <div class="container mx-auto max-w-md p-6 bg-white rounded-xl shadow-lg">
        <h1 class="text-2xl font-bold mb-4 text-center">ImageText Extractor</h1>
        
        <div id="libraryStatus" class="mb-4 text-center text-yellow-600">
            Loading Libraries...
        </div>
        
        <input 
            type="file" 
            id="imageUpload" 
            accept="image/*" 
            class="mb-4 w-full p-2 border rounded"
            disabled
        >
        
        <div id="imagePreview" class="mb-4 text-center">
            <img id="previewImg" class="max-w-full max-h-64 mx-auto hidden" />
        </div>
        
        <button 
            id="processBtn" 
            class="w-full bg-blue-500 text-white py-2 rounded hover:bg-blue-600 disabled:opacity-50"
            disabled
        >
            Extract
        </button>
        
        <div id="loadingIndicator" class="hidden mt-4 text-center">
            <p class="text-blue-600">Processing image...</p>
        </div>
        
        <div id="resultContainer" class="mt-4 bg-gray-100 p-4 rounded">
            <h2 class="font-bold mb-2">Extracted:</h2>
            <pre id="resultText" class="whitespace-pre-wrap break-words"></pre>
        </div>
    </div>

    <script type="module">
        // Import Transformers directly as a module

        import { AutoProcessor, Qwen2VLForConditionalGeneration, RawImage } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.1.0/+esm';

        // DOM Elements
        const libraryStatus = document.getElementById('libraryStatus');
        const imageUpload = document.getElementById('imageUpload');
        const previewImg = document.getElementById('previewImg');
        const processBtn = document.getElementById('processBtn');
        const loadingIndicator = document.getElementById('loadingIndicator');
        const resultText = document.getElementById('resultText');
        const model_id = "onnx-community/Qwen2-VL-2B-Instruct";



        // State
        let model = null;
        let processor = null;
        const conversation = [
                  {
                    role: "user",
                    content: [
                      { type: "image" },
                      { type: "text", text: "Analyze the provided image of pricing for money transfer services. Extract and structure the data into a JSON format with the following fields: Country, Exchange Rate, Service, Currency, Product, and PriceRange.Use the indentation to determine the hierarchy of Services, Products, and PriceRanges. Correct obvious OCR errors and spelling mistakes, Each record in the JSON should follow this structure: {{ \"Country\": string, \"Exchange Rate\": number, \"Service\": string or \"None\",\"Currency\": string,\"Product\": string or \"None\", \"PriceRange\": string or \"None\"}}Rules: 1. Use spatial relationships and indentation to determine the hierarchy: Country > Service > Product > PriceRange. 2. Create separate records for each unique combination of Service, Product, and PriceRange. 3. Maintain the original number of decimal places for exchange rates as shown in the OCR output. 4. Include a Service for all records unless the image contains only Country information. 5. Use \"None\" for Product or PriceRange if not clearly specified. 6. Create separate records for each currency if multiple currencies are present for the same country or service. 7. Correct common OCR errors, such as 'O' to '0', 'l' to '1', etc., while considering the context of financial and geographical terms. 8. Return only a valid JSON array of objects, with no additional text or explanation." }
                        ,
                    ], 
                  },
        ];

        // Initialize the OCR pipeline
        async function initPipeline() {
            try {
                libraryStatus.textContent = 'Initializing Model...';
                libraryStatus.classList.remove('text-yellow-600');
                libraryStatus.classList.add('text-blue-600');

                // Initialize pipeline

                // Load processor and model
                processor = await AutoProcessor.from_pretrained(model_id);
                model = await Qwen2VLForConditionalGeneration.from_pretrained(model_id,{device:'webgpu',});
                // Enable UI elements
                imageUpload.disabled = false;
                libraryStatus.textContent = 'Model Loaded!!!!';
                libraryStatus.classList.remove('text-blue-600');
                libraryStatus.classList.add('text-green-600');
            } catch (error) {
                console.error('Extraction error:', error);
                libraryStatus.textContent = `Error: ${error.message}`;
                libraryStatus.classList.remove('text-blue-600');
                libraryStatus.classList.add('text-red-600');
            }
        }
        
        let imageUrl = null;
        // Image preview
        imageUpload.addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (file) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const dataURL = e.target.result;
                    previewImg.src = dataURL;
                    previewImg.classList.remove('hidden');
                    processBtn.disabled = false;
                    imageUrl = dataURL;       
                };
                reader.readAsDataURL(file);

            }
        });



        // Process image
        processBtn.addEventListener('click', async function() {
            if (!processor) {
                alert('Extraction process not initialized. Please wait....');
                return;
            }

            // Reset UI
            resultText.textContent = '';
            loadingIndicator.classList.remove('hidden');
            processBtn.disabled = true;

            try {
                const image = await (await RawImage.read(imageUrl)).resize(448, 448);
                const text = processor.apply_chat_template(conversation, { add_generation_prompt: true });
                const inputs = await processor(text, image);

                // Perform inference
                const outputs = await model.generate({
                  ...inputs,
                  max_new_tokens: 1024,
                });

                // Decode output
                const result = processor.batch_decode(
                  outputs.slice(null, [inputs.input_ids.dims.at(-1), null]),
                  { skip_special_tokens: true },
                );
                console.log(result[0]);
                
                // Display results
                resultText.textContent = result[0];
            } catch (error) {
                console.error('Processing Error:', error);
                resultText.textContent = `Error: ${error.message}`;
            } finally {
                loadingIndicator.classList.add('hidden');
                processBtn.disabled = false;
            }
        });

        // Initialize pipeline when module loads
        initPipeline();
    </script>
</body>
</html>
