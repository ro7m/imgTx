<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>img-to-text</title>
    <!-- Include ONNX Runtime Web -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.15.0/dist/ort.min.js"></script>
    <style>
        body { 
            font-family: Arial, sans-serif; 
            max-width: 800px; 
            margin: 0 auto; 
            padding: 20px; 
        }
        #preview { 
            max-width: 100%; 
            margin: 20px 0; 
        }
        #results {
            white-space: pre-wrap;
            background-color: #f4f4f4;
            padding: 10px;
            border-radius: 5px;
        }
    </style>
</head>
<body>
    <h1>imgtext-to-text</h1>
    
    <input type="file" id="imageUpload" accept="image/*">
    
    <div>
        <img id="preview" style="display:none;">
    </div>
    
    <div id="status"></div>
    
    <h2>Extracted Data:</h2>
    <pre id="results"></pre>

    <script>
        // Ensure ort is available globally
        window.onload = function() {
            // If ort is not defined, provide a fallback
            if (typeof ort === 'undefined') {
                console.error('ONNX Runtime Web not loaded correctly');
                document.getElementById('status').textContent = 'Failed to load ONNX Runtime. Please check your internet connection.';
                return;
            }

            class MGPStrOCR {
                constructor() {
                    this.session = null;
                    this.modelUrl = 'https://huggingface.co/onnx-community/mgp-str-base/resolve/main/onnx/model_q4f16.onnx?download=true';
                }

                async initialize() {
                    try {
                        // Fetch the model directly from URL
                        const response = await fetch(this.modelUrl);
                        
                        // Check if fetch was successful
                        if (!response.ok) {
                            throw new Error(`HTTP error! status: ${response.status}`);
                        }
                        
                        const modelArrayBuffer = await response.arrayBuffer();

                        // Create ONNX inference session
                        this.session = await ort.InferenceSession.create(modelArrayBuffer, {
                            executionProviders: ['webgpu']
                        });

                        return this;
                    } catch (error) {
                        console.error('Model initialization error:', error);
                        throw error;
                    }
                }

                async processImage(imageFile) {
                    if (!this.session) {
                        throw new Error('Model not initialized');
                    }

                    try {
                        // Convert image to tensor
                        const imageTensor = await this.preprocessImage(imageFile);

                        // Prepare inputs for the model
                        const feeds = {
                            'input': imageTensor
                        };

                        // Run inference
                        const results = await this.session.run(feeds);

                        // Process and return results
                        return this.processResults(results);
                    } catch (error) {
                        console.error('OCR Processing Error:', error);
                        throw error;
                    }
                }

                async preprocessImage(imageFile) {
                    // Create image element and load file
                    const img = document.createElement('img');
                    img.src = URL.createObjectURL(imageFile);
                    
                    await new Promise((resolve, reject) => {
                        img.onload = resolve;
                        img.onerror = reject;
                    });

                    // Create canvas for preprocessing
                    const canvas = document.createElement('canvas');
                    const ctx = canvas.getContext('2d');
                    
                    // Resize and preprocess image
                    canvas.width = 128; 
                    canvas.height = 32;
                    ctx.drawImage(img, 0, 0, 32, 128);

                    // Get image data
                    const imageData = ctx.getImageData(0, 0, 32, 128);
                    
                    // Convert to float32 tensor
                    const data = new Float32Array(imageData.data.length / 4 * 3);
                    for (let i = 0; i < imageData.data.length / 4; i++) {
                        data[i * 3] = (imageData.data[i * 4] / 255 - 0.5) * 2;     // R
                        data[i * 3 + 1] = (imageData.data[i * 4 + 1] / 255 - 0.5) * 2;  // G
                        data[i * 3 + 2] = (imageData.data[i * 4 + 2] / 255 - 0.5) * 2;  // B
                    }

                    // Create ONNX tensor
                    return new ort.Tensor('float32', data, [1, 3, 32, 128]);
                }

                processResults(results) {
                    // Log raw results for debugging
                    console.log('Raw inference results:', results);

                    // Basic result processing
                    return {
                        raw: results,
                        message: 'Results processing needs customization for this specific model'
                    };
                }
            }

            // DOM Elements
            const imageUpload = document.getElementById('imageUpload');
            const preview = document.getElementById('preview');
            const statusDiv = document.getElementById('status');
            const resultsDiv = document.getElementById('results');

            // Initialize OCR
            let ocrProcessor;
            (async () => {
                try {
                    statusDiv.textContent = 'Loading ONNX model from URL...';
                    ocrProcessor = new MGPStrOCR();
                    await ocrProcessor.initialize();
                    statusDiv.textContent = 'Model ready!';
                } catch (error) {
                    statusDiv.textContent = `Model load error: ${error.message}`;
                    console.error(error);
                }
            })();

            // File Upload Event Listener
            imageUpload.addEventListener('change', async (event) => {
                const file = event.target.files[0];
                
                if (!file) return;

                // Clear previous results
                resultsDiv.textContent = '';
                statusDiv.textContent = '';

                // Show preview
                preview.src = URL.createObjectURL(file);
                preview.style.display = 'block';

                try {
                    // Update status
                    statusDiv.textContent = 'Processing image...';

                    // Perform OCR
                    const result = await ocrProcessor.processImage(file);

                    // Display results
                    resultsDiv.textContent = JSON.stringify(result, null, 2);

                    // Update status
                    statusDiv.textContent = 'Processing Complete!';
                } catch (error) {
                    statusDiv.textContent = `Processing Error: ${error.message}`;
                    console.error(error);
                }
            });
        }
    </script>
</body>
</html>
